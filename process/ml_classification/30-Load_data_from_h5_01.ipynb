{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime as dt\n",
    "\n",
    "from itertools import repeat\n",
    "import concurrent.futures\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 100/1109 [01:32<13:47,  1.22it/s]/tmp/ipykernel_7047/1679797792.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f] = list(hf[f])\n",
      "100%|██████████| 1109/1109 [15:10<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190954, 1109)\n"
     ]
    }
   ],
   "source": [
    "start = dt.now()\n",
    "print('Job start at : ', start)\n",
    "\n",
    "filename = '../data/preprocess/ALL/augmentation/export/data_all_all_graycoprops_lpb_histogram_hue_moment_haralick_histogram_hsv_histogram_lab_pyfeats.h5'\n",
    "\n",
    "df_features = pd.DataFrame()\n",
    "\n",
    "hf = h5py.File(filename, 'r')\n",
    "\n",
    "features = list(hf.keys())\n",
    "\n",
    "features_lst = []\n",
    "features.sort()\n",
    "\n",
    "for i in range((len(features) // 20 + 1)):\n",
    "    features_lst.append(features[20*i:20*(i+1)])\n",
    "\n",
    "\n",
    "\n",
    "def convert_to_df(lst):\n",
    "    df = pd.DataFrame()\n",
    "    for f in lst:\n",
    "        df[f] = list(hf[f])\n",
    "\n",
    "    return df\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    results = list(tqdm(executor.map(convert_to_df, features_lst), total=len(features_lst)))\n",
    "\n",
    "hf.close()\n",
    "\n",
    "df_features = pd.DataFrame()\n",
    "\n",
    "for df in results:\n",
    "    df_features = pd.concat([df_features, df], axis=1)\n",
    "\n",
    "df =df_features.drop_duplicates()\n",
    "\n",
    "print('Duplicates rows : ', df.shape, df_features.shape, (df_features.shape[1]-df.shape[1]))\n",
    "\n",
    "df_features['classes'] = df_features.classes.apply(lambda l: l.decode(\"utf-8\"))\n",
    "df_features = df_features.copy()\n",
    "print(df_features.shape)\n",
    "\n",
    "features = [f for f in df_features.columns if f != 'classes']\n",
    "df_features[features]=MinMaxScaler().fit_transform(df_features[features].to_numpy()).astype(np.float32)\n",
    "\n",
    "df_features.to_pickle('../data/preprocess/ALL/augmentation/export/data_all_all_graycoprops_lpb_histogram_hue_moment_haralick_histogram_hsv_histogram_lab_pyfeats.pkl')\n",
    "\n",
    "print('Job ended at ', dt.now(), '\\tIt took : ', dt.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.21739130434783"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1109 / 23"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db89e261e019b1a211d3398e2504286fa00f0bcce27fd7af250a272a37a3260b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
